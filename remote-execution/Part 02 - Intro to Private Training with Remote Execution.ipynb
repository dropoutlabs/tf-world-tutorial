{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Intro to Private Training with Remote Execution\n",
    "\n",
    "**Note that this tutorial was originally designed part of [OpenMined PySyft-TensorFlow tutorials](https://github.com/OpenMined/PySyft-TensorFlow/tree/master/examples)**\n",
    "\n",
    "In the last section, we learned about PointerTensors, which create the underlying infrastructure we need for privacy preserving Deep Learning. In this section, we're going to see how to use these basic tools to train our first deep learning model using remote execution.\n",
    "\n",
    "### Why use remote execution?\n",
    "\n",
    "Let's say you are an AI startup who wants to build a deep learning model to detect [diabetic retinopathy (DR)](https://ai.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html), which is the fastest growing cause of blindness. Before training your model, the first step would be to acquire a dataset of retinopathy images with signs of DR. One approach could be to work with a hospital and ask them to send you a copy of this dataset. However because of the sensitivity of the patients' data, the hospital might be exposed to liability risks.\n",
    "\n",
    "\n",
    "That's where remote execution comes into the picture. Instead of bringing training data to the model (a central server), you bring the model to the training data (wherever it may live). In this case, it would be the hospital.\n",
    "\n",
    "The idea is that this allows whoever is creating the data to own the only permanent copy, and thus maintain control over who ever has access to it. Pretty cool, eh?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.1 - Private Training on Fashion MNIST\n",
    "\n",
    "For this tutorial, we will train a model on the [Fashion MNIST dataset](https://www.tensorflow.org/datasets/catalog/fashion_mnist) to classify images of clothing.\n",
    "\n",
    "We can assume that we have a remote worker named Bob who owns the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import syft as sy\n",
    "\n",
    "hook = sy.TensorFlowHook(tf)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the Fashion MNIST data from `tensorflow_datasets`. In the cell below, we are converting the data from [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to `tf.Tensor` in order to have the PySyft functionalities. \n",
    "\n",
    "Note that adding tf.data.Dataset support is on the roadmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load(\"fashion_mnist:3.0.0\")\n",
    "\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "# we are generating this large batch to convert\n",
    "# the tf.data.Dataset into tf.Tensor\n",
    "train_dataset = next(iter(train_dataset.batch(60000)))\n",
    "test_dataset = next(iter(test_dataset.batch(10000)))\n",
    "\n",
    "x_train, y_train = train_dataset['image'], train_dataset['label']\n",
    "x_test, y_test = test_dataset['image'], test_dataset['label']\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32) / 255.0\n",
    "x_test = tf.cast(x_test, tf.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As decribed in Part 1, we can send this data to Bob with the `send` method on the `tf.Tensor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ptr = x_train.send(bob)\n",
    "y_train_ptr = y_train.send(bob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We have everything to start experimenting. To train our model on Bob's machine, we just have to perform the following steps:\n",
    "\n",
    "- Define a model, including optimizer and loss\n",
    "- Send the model to Bob\n",
    "- Start the training process\n",
    "- Get the trained model back\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28 ,1)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with optimizer, loss and metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have defined your model, you can simply send it to Bob calling the `send` method. It's the exact same process as sending a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ppml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/ppml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmpvoiw62h1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmpvoiw62h1/assets\n"
     ]
    }
   ],
   "source": [
    "model_ptr = model.send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[ObjectPointer | me:50838506757 -> bob:19824984963]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a pointer pointing to the model on Bob's machine. We can validate that's the case by inspecting the attribute `_objects` on the virtual worker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.saving.saved_model.load.Sequential object at 0x162f406d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects[model_ptr.id_at_location]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ready to start training our model on this remote dataset. You can call `fit` and pass `x_train_ptr` `y_train_ptr` which are pointing to Bob's data. Note that's the exact same interface as normal `tf.keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 12s 245us/sample - loss: 0.5102 - accuracy: 0.8210 - val_loss: 0.3453 - val_accuracy: 0.8737\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 11s 234us/sample - loss: 0.3237 - accuracy: 0.8839 - val_loss: 0.2813 - val_accuracy: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x162bd5b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ptr.fit(x_train_ptr, y_train_ptr, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! you have trained your model acheiving an accuracy greater than 88%.\n",
    "\n",
    "You can get your trained model back by just calling `get` on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmp63zp9g4f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmp63zp9g4f/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.saving.saved_model.load.Sequential object at 0x15fd6b550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gotten = model_ptr.get()\n",
    "\n",
    "model_gotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to see if your model can generalize by assessing its accuracy on an holdout dataset. You can simply call `evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.6186 - accuracy: 0.8909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3122893062591553, 0.8909]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gotten.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom! The model remotely trained on Bob's data is more than 87% accurate on this holdout dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model doesn't fit into the Sequential paradigm, you can use Keras's functional API, or even subclass [tf.keras.Model](https://www.tensorflow.org/guide/keras/custom_layers_and_models#building_models) to create custom models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmprtukf9dn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/1c/vs6gvqqs1lngfqs6fkjrcclm0000gn/T/tmprtukf9dn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 11s 229us/sample - loss: 0.4514 - accuracy: 0.8399 - val_loss: 0.3187 - val_accuracy: 0.8848\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 11s 234us/sample - loss: 0.3056 - accuracy: 0.8899 - val_loss: 0.2942 - val_accuracy: 0.8886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15afacbe0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomModel, self).__init__(name='custom_model')\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv_1 = Conv2D(16, 3, padding='same', activation='relu', input_shape=(28, 28 ,1))\n",
    "        self.maxpool_1 = MaxPooling2D()\n",
    "        self.conv_2 = Conv2D(32, 3, padding='same', activation='relu')\n",
    "        self.maxpool_2 = MaxPooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_1 = Dense(128, activation='relu')\n",
    "        self.dense_2 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_1(x)\n",
    "        return self.dense_2(x)\n",
    "              \n",
    "model = CustomModel(10)\n",
    "\n",
    "# need to call the model on dummy data before sending it\n",
    "# in order to set the input shape (required when saving to SavedModel)\n",
    "model.predict(tf.ones([1, 28, 28, 1]))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_ptr = model.send(bob)\n",
    "\n",
    "model_ptr.fit(x_train_ptr, y_train_ptr, epochs=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Done!\n",
    "\n",
    "And voilà! We have trained a Deep Learning model on Bob's data by sending the model to him. Never in this process do we ever see or request access to the underlying training data! We preserve the privacy of Bob!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join OpenMined Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
