{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: The Basic Tools of Private Deep Learning -- TensorFlow edition!\n",
    "\n",
    "\n",
    "**Note that this tutorial was originally designed part of [OpenMined PySyft-TensorFlow tutorials](https://github.com/OpenMined/PySyft-TensorFlow/tree/master/examples)**\n",
    "\n",
    "Welcome to PySyft's introductory tutorial for privacy preserving, decentralized deep learning. This series of notebooks is a step-by-step guide for you to get to know the new tools and techniques required for doing deep learning on secret/private data/models without centralizing them under one authority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Hook TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add PySyft functionalities to TensorFlow, you just have to call `hook = sy.TensorFlowHook(tf)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(5,), dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to see if things work\n",
    "import tensorflow as tf\n",
    "import syft as sy\n",
    "hook = sy.TensorFlowHook(tf)\n",
    "\n",
    "tf.constant([1, 2, 3, 4, 5.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this cell executed, then you're off to the races! Let's do this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Basic Tools of Private, Decentralized Data Science\n",
    "\n",
    "So - the first question you may be wondering is - How in the world do we train a model on data we don't have access to? \n",
    "\n",
    "Well, the answer is surprisingly simple. If you're used to working in TensorFlow, then you're used to working with tf.Tensor objects like these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6, shape=(5,), dtype=float32, numpy=array([ 2.,  4.,  6.,  8., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3, 4, 5.])\n",
    "y = x + x\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, using these super fancy (and powerful!) tensors is important, but also requires you to have the data on your local machine. This is where our journey begins. \n",
    "\n",
    "# Section 1.1 - Sending Tensors to Bob's Machine\n",
    "\n",
    "Whereas normally we would perform data science / deep learning on the machine which holds the data, now we want to perform this kind of computation on some **other** machine. More specifically, we can no longer simply assume that the data is on our local machine.\n",
    "\n",
    "Thus, instead of using TensorFlow tensors, we're now going to work with **pointers** to tensors. Let me show you what I mean. First, let's create a \"pretend\" machine owned by a \"pretend\" person - we'll call him Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say Bob's machine is on another planet - perhaps on Mars! But, at the moment the machine is empty. Let's create some data so that we can send it to Bob and learn about pointers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1., 2., 3., 4., 5.])\n",
    "y = tf.constant([1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now - let's send our tensors to Bob!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptr = x.send(bob)\n",
    "y_ptr = y.send(bob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOM! Now Bob has two tensors! Don't believe me? Have a look for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{41987490178: <tf.Tensor: id=11, shape=(5,), dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>,\n",
       " 72927188351: <tf.Tensor: id=15, shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:86379356515 -> bob:14242433809]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ptr = x_ptr + x_ptr\n",
    "z_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{41987490178: <tf.Tensor: id=11, shape=(5,), dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>,\n",
       " 72927188351: <tf.Tensor: id=15, shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " 14242433809: <tf.Tensor: id=17, shape=(5,), dtype=float32, numpy=array([ 2.,  4.,  6.,  8., 10.], dtype=float32)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice something. When we called `x.send(bob)` it returned a new object that we called `x_ptr`. This is our first *pointer* to a tensor. Pointers to tensors do NOT actually hold data themselves. Instead, they simply contain metadata about a tensor (with data) stored on another machine. The purpose of these tensors is to give us an intuitive API to tell the other machine to compute functions using this tensor. Let's take a look at the metadata that pointers contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:86379356515 -> bob:14242433809]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out that metadata!\n",
    "\n",
    "There are two main attributes specific to pointers:\n",
    "\n",
    "- `x_ptr.location : bob`, the location, a reference to the location that the pointer is pointing to\n",
    "- `x_ptr.id_at_location : <random integer>`, the id where the tensor is stored at location\n",
    "\n",
    "They are printed in the format `<id_at_location>@<location>`\n",
    "\n",
    "There are also other more generic attributes:\n",
    "- `x_ptr.id : <random integer>`, the id of our pointer tensor, it was allocated randomly\n",
    "- `x_ptr.owner : \"me\"`, the worker which owns the pointer tensor, here it's the local worker, named \"me\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:bob #objects:3>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:bob #objects:3>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob == x_ptr.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41987490178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr.id_at_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:me #objects:0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr.owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder why the local worker which owns the pointer is also a VirtualWorker, although we didn't create it.\n",
    "Fun fact, just like we had a VirtualWorker object for Bob, we (by default) always have one for us as well. This worker is automatically created when we construct `hook = sy.TensorFlowHook(tf)` and so you don't usually have to create it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:me #objects:0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me = sy.local_worker\n",
    "me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me == x_ptr.owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, just like we can call .send() on a tensor, we can call .get() on a pointer to a tensor to get it back!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21, shape=(5,), dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(5,), dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ptr.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=27, shape=(5,), dtype=float32, numpy=array([ 2.,  4.,  6.,  8., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ptr.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see... Bob no longer has the tensors anymore!!! They've moved back to our machine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2 - Arithmetic with Tensor Pointers\n",
    "\n",
    "So, sending and receiving tensors from Bob is great, but this is hardly Deep Learning! We want to be able to perform tensor _operations_ on remote tensors. Fortunately, tensor pointers make this quite easy! You can just use pointers like you would normal tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 4.]\n",
      " [6. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 3., 4.])\n",
    "x_ptr = x.send(bob)\n",
    "\n",
    "y_ptr = x_ptr + x_ptr\n",
    "\n",
    "y = tf.reshape(y_ptr, [2, 2])\n",
    "id = tf.constant([[1., 0.], [0., 1.]]).send(bob)\n",
    "\n",
    "z = tf.matmul(y, id)\n",
    "\n",
    "print(z.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voilà! \n",
    "\n",
    "Behind the scenes, something very powerful happened. Instead of doing a matrix multiplication between x and an identity matrix locally, several commands were serialized and sent to Bob, who performed the computation remotely on his machine until we called .get() on z to get the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "You can perform similar operations on `tf.Variable` as well. Here is an example of manual differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated:  <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[-0.28401625],\n",
      "       [ 0.6857992 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "x = tf.expand_dims(id[0], 0)\n",
    "\n",
    "w_init = tf.initializers.glorot_normal()\n",
    "w = tf.Variable(w_init(shape=(2, 1), dtype=tf.float32)).send(bob)\n",
    "z = tf.matmul(x, w)\n",
    "\n",
    "# # Manual differentiation & update\n",
    "dzdx = tf.transpose(x)\n",
    "w.assign_sub(dzdx)\n",
    "\n",
    "print(\"Updated: \", w.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Automatic differentiation](https://www.tensorflow.org/tutorials/customization/autodiff) with `tf.GradientTape` is on the roadmap!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join OpenMined Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
