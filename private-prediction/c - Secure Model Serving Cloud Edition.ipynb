{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Secure Model Serving Cloud Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore how easy it will be to modify Part 2 to support predictions in the cloud. We'll point out the differences below.\n",
    "\n",
    "The first steps are to set up the cloud instances. There are few prerequisites that need to be setup prior to launching the cloud instances. This tutorial uses Google Cloud so you'll need an account set up there and need to have the gcloud command-line tool installed.\n",
    "\n",
    "See [here](https://github.com/dropoutlabs/tf-world-tutorial/blob/master/private-prediction/CLOUD.md) for more details about installing the gcloud command-line tool and launching the instances.\n",
    "\n",
    "Once that is completed you can continue with the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tf_encrypted as tfe\n",
    "import tf_encrypted.keras.backend as KE\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jasonmancuso/tf-world/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "trained_model = '../saved_fl_model'\n",
    "model = tf.keras.models.load_model(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only major change is here. We can just use the saved configuration file from setting up the cloud instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tfe.RemoteConfig.load('/tmp/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe.set_config(config)\n",
    "tfe.set_protocol(tfe.protocol.SecureNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert TF Keras into TFE Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to `tfe.keras.models.clone_model` you can convert automatically the TF Keras model into a TFE Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tfe.protocol.SecureNN():\n",
    "    tfe_model = tfe.keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a new `tfe.serving.QueueServer` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfe.serving.QueueServer` will launch a serving queue, so that the TFE servers can accept prediction requests on the secured model from external clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a new tfe.serving.QueueServer for the shared TFE model\n",
    "q_input_shape = (1, 784)\n",
    "q_output_shape = (1, 10)\n",
    "\n",
    "server = tfe.serving.QueueServer(\n",
    "    input_shape=q_input_shape, output_shape=q_output_shape, computation_fn=tfe_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = KE.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_ix = 1\n",
    "\n",
    "def step_fn():\n",
    "    global request_ix\n",
    "    print(\"Served encrypted prediction {i} to client.\".format(i=request_ix))\n",
    "    request_ix += 1\n",
    "\n",
    "server.run(\n",
    "    sess,\n",
    "    num_steps=3,\n",
    "    step_fn=step_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to move back to the **c - Private Prediction Client** notebook to request some private predictions. Make sure to restart the kernel and reset the cells if you've already run that notebook in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to shut down your Google Cloud instances by following the instructions [here](TODO)."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
